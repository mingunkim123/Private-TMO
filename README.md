ğŸ›¡ï¸ Jetson-Secure-TMO: Privacy-Preserving Offloading for Personalized LLMs

ì´ í”„ë¡œì íŠ¸ëŠ” TMO (Task/Model Offloading) í”„ë ˆì„ì›Œí¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, Jetson Orin Nano (8GB) í™˜ê²½ì—ì„œ TensorRT-LLMì„ ì§€ì›í•˜ë„ë¡ ì¶”ë¡  ì—”ì§„ì„ ìµœì í™”í•˜ê³  ê³„ì¸µì  ê°œì¸í™”(Hierarchical Personalization) ë° ê°œì¸ì •ë³´ ë³´í˜¸(Privacy Guard) ê¸°ëŠ¥ì„ ì¶”ê°€í•œ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
ğŸš€ Key Features

    Edge-Cloud Collaboration: ì§€ì—° ì‹œê°„(Latency)ê³¼ ë¹„ìš©(Cost)ì„ ê³ ë ¤í•˜ì—¬ ë¡œì»¬(Jetson)ê³¼ í´ë¼ìš°ë“œ ê°„ì˜ ì¶”ë¡  ì‘ì—…ì„ ë™ì ìœ¼ë¡œ ìŠ¤ì¼€ì¤„ë§í•©ë‹ˆë‹¤.

Hierarchical LoRA Selection: ì‚¬ìš©ìì˜ ì‘ì—… ì„±ê²©ê³¼ ë¯¼ê°ë„ì— ë”°ë¼ Personal / Group / General ê³„ì¸µì˜ LoRA ì–´ëŒ‘í„°ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ êµì²´í•©ë‹ˆë‹¤.

Privacy-First Guard: BERT ê¸°ë°˜ NER ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì§ˆë¬¸ ë‚´ ê°œì¸ ì‹ë³„ ì •ë³´(PII)ë¥¼ íƒì§€í•˜ê³ , ë³´ì•ˆ ì ìˆ˜ì— ë”°ë¼ í´ë¼ìš°ë“œ ì „ì†¡ ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.

Hardware Optimization: ì ¯ìŠ¨ ì˜¤ë¦° ë‚˜ë…¸ì˜ ì œí•œëœ ë©”ëª¨ë¦¬(8GB) ë‚´ì—ì„œ ì›í™œí•œ êµ¬ë™ì„ ìœ„í•´ INT4 ì–‘ìí™” ë° TensorRT-LLM ê°€ì†ì„ ì ìš©í–ˆìŠµë‹ˆë‹¤.

ğŸ—ï¸ System Architecture

ë³¸ ì‹œìŠ¤í…œì€ ë‹¨ìˆœí•œ ëª¨ë¸ ì‹¤í–‰ì„ ë„˜ì–´, ë‹¤ìŒì˜ í•™ìˆ ì  ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•©í•˜ì—¬ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤:

    Context-Aware Policy: ì§ˆë¬¸ì˜ ë³µì¡ì„±ê³¼ ì˜ˆì‚° ì œì•½ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ëª¨ë¸ì„ ì„ íƒí•©ë‹ˆë‹¤ (ì°¸ê³ : Efficient Contextual LLM Cascades ).

Personalization-Generalization Split: ë¯¼ê°í•œ ê°œì¸ ì •ë³´ëŠ” ë¡œì»¬ ì–´ëŒ‘í„°ì—ì„œ ì²˜ë¦¬í•˜ê³ , ì¼ë°˜ì ì¸ ì§€ì‹ì€ í´ë¼ìš°ë“œ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì •ë³´ ë¹„ëŒ€ì¹­ì„ í•´ê²°í•©ë‹ˆë‹¤.

Cost-Performance Optimization: FrugalGPTì˜ ì „ëµì„ ì°¨ìš©í•˜ì—¬ ì‘ë‹µ í’ˆì§ˆì„ ìœ ì§€í•˜ë©´ì„œë„ í´ë¼ìš°ë“œ API í˜¸ì¶œ ë¹„ìš©ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤ (ì°¸ê³ : FrugalGPT ).

ğŸ“š References & Acknowledgments

ë³¸ í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒì˜ ì—°êµ¬ë“¤ì„ ì°¸ê³ í•˜ì—¬ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤:

    TMO Framework: [Original Repository Link]

    MoA-OFF: Adaptive Heterogeneous Modality-Aware Offloading with Edge-Cloud Collaboration.

PerLLM: Personalized Inference Scheduling with Edge-Cloud Collaboration.

FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance.

Federated Split Learning: Joint Personalization-Generalization for Inference-Stage Optimization.

Privacy-Preserving Personalization: Hierarchical User Profiling Methods for Privacy Protection.
