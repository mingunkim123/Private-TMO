"This project is based on the TMO framework (Link to Original Repo). We modified the inference engine to support Jetson Orin Nano with TensorRT-LLM."

Reference
1.MOA-OFF: ADAPTIVE HETEROGENEOUS MODALITY-AWARE OFFLOADING WITH
EDGE-CLOUD COLLABORATION FOR EFFICIENT MULTIMODAL LLM INFERENCE(이미지의 복잡성 분석)

PerLLM: Personalized Inference Scheduling with
Edge-Cloud Collaboration for Diverse LLM Services(통계적 알고리즘(CS-UCB))
