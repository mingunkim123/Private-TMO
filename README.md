"This project is based on the TMO framework (Link to Original Repo). We modified the inference engine to support Jetson Orin Nano with TensorRT-LLM."

Reference
1.MOA-OFF: ADAPTIVE HETEROGENEOUS MODALITY-AWARE OFFLOADING WITH
EDGE-CLOUD COLLABORATION FOR EFFICIENT MULTIMODAL LLM INFERENCE(이미지의 복잡성 분석)

PerLLM: Personalized Inference Scheduling with
Edge-Cloud Collaboration for Diverse LLM Services(통계적 알고리즘(CS-UCB))

Efficient Contextual LLM Cascades through
Budget-Constrained Policy Learning(금전적 예산과 지연 시간 제약 안에서 질문의 문맥을 파악)

FrugalGPT: How to Use Large Language Models
While Reducing Cost and Improving Performance(모델 순차적 선택)

Federated Split Learning With Joint
Personalization-Generalization for Inference-Stage
Optimization in Wireless Edge Networks(개인화 모델과 일반화 모델의 분리)
